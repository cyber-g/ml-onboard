{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kqf1Ul7Hnenb",
    "outputId": "578115a8-93ec-4329-c64e-2a8736070df5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Useful function for dealing with data, and classical machine learning\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../src'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from helpers import (  # noqa E402\n",
    "    read_data,\n",
    "    show_basic_dataframe_info,\n",
    "    plot_activity,\n",
    "    create_segments_and_labels,\n",
    "    save_converted_model)\n",
    "\n",
    "# Set some standard parameters upfront\n",
    "pd.options.display.float_format = '{:.1f}'.format\n",
    "sns.set()  # Default seaborn look and feel\n",
    "plt.style.use('ggplot')\n",
    "print('keras version ', keras.__version__)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From https://github.com/ni79ls/har-keras-cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sFPykW3yqgcu"
   },
   "outputs": [],
   "source": [
    "# The number of steps within one time segment\n",
    "TIME_PERIODS = 80\n",
    "# The steps to take from one segment to the next; if this value is equal to\n",
    "# TIME_PERIODS, then there is no overlap between the segments\n",
    "STEP_DISTANCE = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LVXyaNdSq2os"
   },
   "source": [
    "Load, inspect and transform data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1CDOUpDxq6x1",
    "outputId": "26dca29b-3525-48fc-df89-7de14f8ed9c0"
   },
   "outputs": [],
   "source": [
    "# Load data set containing all the data from csv\n",
    "df = read_data('../data/WISDM.txt', column_names=[\n",
    "    'user-id',\n",
    "    'activity',\n",
    "    'timestamp',\n",
    "    'x-axis',\n",
    "    'y-axis',\n",
    "    'z-axis'])\n",
    "\n",
    "# Describe the data\n",
    "show_basic_dataframe_info(df, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels from data\n",
    "LABELS = df[\"activity\"].unique()\n",
    "print(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 608
    },
    "id": "g2oyoE8IrEIh",
    "outputId": "0e803f70-6255-4732-8fe2-39098693221d"
   },
   "outputs": [],
   "source": [
    "df['activity'].value_counts().plot(kind='bar',\n",
    "                                   title='Training Examples by Activity Type')\n",
    "plt.show()\n",
    "\n",
    "df['user-id'].value_counts().plot(kind='bar',\n",
    "                                  title='Training Examples by User')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "MtdbjzgDrdzS",
    "outputId": "e183e973-e3b9-438c-9be1-7ae16cfa6971"
   },
   "outputs": [],
   "source": [
    "for activity in np.unique(df[\"activity\"]):\n",
    "    subset = df[df[\"activity\"] == activity][:180]\n",
    "    plot_activity(activity, subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uyQZUDNcrhPF"
   },
   "outputs": [],
   "source": [
    "# Define column name of the label vector\n",
    "LABEL = \"ActivityEncoded\"\n",
    "# Transform the labels from String to Integer via LabelEncoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "# Add a new column to the existing DataFrame with the encoded values\n",
    "df[LABEL] = le.fit_transform(df[\"activity\"].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fp2Gk4EAroy3"
   },
   "outputs": [],
   "source": [
    "# Differentiate between test set and training set\n",
    "df_test = df[df['user-id'] % 5 == 0]\n",
    "df_train = df[df['user-id'] % 5 != 0]\n",
    "\n",
    "df_train = df_train.round({'x-axis': 6, 'y-axis': 6, 'z-axis': 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the training data into segments\n",
    "# so that they can be processed by the network\n",
    "x_train, y_train = create_segments_and_labels(df_train,\n",
    "                                              TIME_PERIODS,\n",
    "                                              STEP_DISTANCE,\n",
    "                                              LABEL)\n",
    "\n",
    "df_test = df_test.round({'x-axis': 6, 'y-axis': 6, 'z-axis': 6})\n",
    "\n",
    "x_test, y_test = create_segments_and_labels(df_test,\n",
    "                                            TIME_PERIODS,\n",
    "                                            STEP_DISTANCE,\n",
    "                                            LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "x_train, y_train = shuffle(x_train, y_train)\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "df_train['activity'].value_counts().plot(\n",
    "    kind='bar',\n",
    "    title='Training Examples by Activity Type')\n",
    "df_test['activity'].value_counts().plot(\n",
    "    kind='bar',\n",
    "    title='Training Examples by Activity Type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Me6O5CLPry5h",
    "outputId": "6daaa5ce-538a-459d-ad47-8d5a25ba0f46"
   },
   "outputs": [],
   "source": [
    "# Inspect x data\n",
    "print('x_train shape: ', x_train.shape)\n",
    "print(x_train.shape[0], 'training samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Inspect y data\n",
    "print('y_train shape: ', y_train.shape)\n",
    "\n",
    "# Set input & output dimensions\n",
    "num_time_periods, num_sensors = x_train.shape[1], x_train.shape[2]\n",
    "num_classes = le.classes_.size\n",
    "print(list(le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iRE9ZAEKsmnV",
    "outputId": "40ba23b2-a776-4749-81d4-24219c043d79"
   },
   "outputs": [],
   "source": [
    "input_shape = (TIME_PERIODS, num_sensors)\n",
    "\n",
    "y_train_one_hot = pd.get_dummies(y_train)\n",
    "print('New y_train shape: ', y_train_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eWsX8eoCwgyK"
   },
   "source": [
    "# Create neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6xvHOb17uP5v",
    "outputId": "8f8bdf6d-0aa5-45ee-9ede-0ff6f9ea77d1"
   },
   "outputs": [],
   "source": [
    "weights = {c: len(y_train) / (y_train == c).sum() for c in range(num_classes)}\n",
    "\n",
    "# DEFINE NETWORK PARAMETERS\n",
    "trainSplitRatio = 0.7  # split ratio for test and validation\n",
    "window_size = TIME_PERIODS  # Length of time slice.\n",
    "# Actitrac was recorded at 20Hz\n",
    "numFilters1 = 100  # number of filters in first Conv1D layer\n",
    "kernelSize = 10  # kernal size of the Conv2D layer\n",
    "batchSize = 10\n",
    "numNueronsFCL2 = 160  # number of filters in fully connected output layer\n",
    "dropout = 0.5  # dropout rate.\n",
    "# % of neurons converted to 0 weight before softmax\n",
    "\n",
    "norm_layer = Normalization()\n",
    "norm_layer.adapt(x_train)\n",
    "model_m = Sequential()\n",
    "# model_m.add(norm_layer)\n",
    "model_m.add(Conv1D(14, 10, activation='relu', input_shape=input_shape))\n",
    "# model_m.add(Conv1D(100, 10, activation='relu'))\n",
    "model_m.add(MaxPooling1D(3))\n",
    "model_m.add(Conv1D(16, 10, activation='relu'))\n",
    "# model_m.add(Conv1D(160, 10, activation='relu'))\n",
    "model_m.add(GlobalAveragePooling1D())\n",
    "model_m.add(Dropout(dropout))\n",
    "model_m.add(Dense(num_classes, activation='softmax'))\n",
    "print(model_m.summary())\n",
    "\n",
    "# The EarlyStopping callback monitors training accuracy:\n",
    "# if it fails to improve for two consecutive epochs,\n",
    "# training stops early\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='best_model.{epoch:02d}-{val_loss:.2f}.h5',\n",
    "        monitor='val_loss', save_best_only=True),\n",
    "    keras.callbacks.EarlyStopping(monitor='accuracy', patience=5)\n",
    "]\n",
    "\n",
    "model_m.compile(loss='categorical_crossentropy',\n",
    "                optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Hyper-parameters\n",
    "BATCH_SIZE = 200\n",
    "EPOCHS = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mr2vIulqwukD"
   },
   "source": [
    "# Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CxTd7v9ctJ7C",
    "outputId": "3a3de0e8-bf4d-40e2-dcb1-afc4a4369887"
   },
   "outputs": [],
   "source": [
    "# Enable validation to use ModelCheckpoint and EarlyStopping callbacks.\n",
    "if 'SAVED_MODEL_PATH' not in os.environ:\n",
    "    history = model_m.fit(x_train,\n",
    "                          y_train_one_hot,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          epochs=EPOCHS,\n",
    "                          callbacks=callbacks_list,\n",
    "                          validation_split=0.2,\n",
    "                          # class_weight=weights,\n",
    "                          verbose=1)\n",
    "    # summarize history for accuracy and loss\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(history.history['accuracy'], \"g--\",\n",
    "             label=\"Accuracy of training data\")\n",
    "    plt.plot(history.history['val_accuracy'], \"g\",\n",
    "             label=\"Accuracy of validation data\")\n",
    "    plt.plot(history.history['loss'], \"r--\",\n",
    "             label=\"Loss of training data\")\n",
    "    plt.plot(history.history['val_loss'], \"r\",\n",
    "             label=\"Loss of validation data\")\n",
    "    plt.title('Model Accuracy and Loss')\n",
    "    plt.ylabel('Accuracy and Loss')\n",
    "    plt.xlabel('Training Epoch')\n",
    "    plt.ylim(0)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "else:\n",
    "    model_m = load_model(os.environ['SAVED_MODEL_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can save the trained model by running the following:\n",
    "# from tensorflow.keras.models import save_model\n",
    "# save_model(model_m, '../models/cnn/saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQVv2m40ufje"
   },
   "source": [
    "# Check against test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AIhaGD5FueaV",
    "outputId": "21e8339d-5272-455d-acf4-f195cc25a730"
   },
   "outputs": [],
   "source": [
    "y_test_neural = pd.get_dummies(y_test)\n",
    "\n",
    "score = model_m.evaluate(x_test, y_test_neural, verbose=1)\n",
    "\n",
    "print(f\"\\nAccuracy on test data: {score[1] * 100:.1f}%\")\n",
    "print(f\"\\nLoss on test data: {score[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = model_m.predict(x_test)\n",
    "# Take the class with the highest probability from the test predictions\n",
    "max_y_pred_test = np.argmax(y_pred_test, axis=1)\n",
    "\n",
    "cf_matrix = pd.DataFrame(confusion_matrix(y_test, max_y_pred_test),\n",
    "                         columns=LABELS, index=LABELS)\n",
    "sns.heatmap(cf_matrix / np.sum(cf_matrix), annot=True, fmt='.2%',\n",
    "            cmap='Greens')\n",
    "\n",
    "print(classification_report(y_test, max_y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_dataset():\n",
    "    for x in tf.data.Dataset.from_tensor_slices((x_train)).batch(1).take(100):\n",
    "        yield [tf.dtypes.cast(x, tf.float32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_m)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8  # or tf.uint8\n",
    "converter.inference_output_type = tf.int8  # or tf.uint8\n",
    "converter.representative_dataset = representative_dataset\n",
    "converted = converter.convert()\n",
    "save_converted_model(converted, \"wisdm_tflite\", LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that we can load the converted model\n",
    "interpreter = tf.lite.Interpreter(\"../models/wisdm_tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "print(\"Input:\", interpreter.get_input_details())\n",
    "print(\"Output:\", interpreter.get_output_details())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(interpreter.get_input_details()[0]['quantization'])\n",
    "print(interpreter.get_output_details()[0]['quantization'])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "WISDM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
