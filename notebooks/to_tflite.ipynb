{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dh4AXGuHWeu1"
   },
   "source": [
    "## Setup Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tx9lOPWh9grN"
   },
   "source": [
    "Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "53PBJBv1jEtJ"
   },
   "outputs": [],
   "source": [
    "# TensorFlow is an open source machine learning library\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# Numpy is a math library\n",
    "import numpy as np\n",
    "# Pandas is a data manipulation library\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Useful function for dealing with data, and classical machine learning\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# Define paths to model files\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../src'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from helpers import (read_data,  # noqa E402\n",
    "                     create_segments_and_labels,\n",
    "                     save_converted_model,\n",
    "                     compare)\n",
    "\n",
    "# Set some standard parameters upfront\n",
    "pd.options.display.float_format = '{:.1f}'.format\n",
    "sns.set()  # Default seaborn look and feel\n",
    "plt.style.use('ggplot')\n",
    "print('keras version ', keras.__version__)\n",
    "%matplotlib inline\n",
    "\n",
    "MODELS_DIR = '../models/cnn/'\n",
    "MODEL_TF = MODELS_DIR + 'saved2'\n",
    "MODEL_NO_QUANT_TFLITE = MODELS_DIR + 'model_no_quant.tflite'\n",
    "MODEL_TFLITE = MODELS_DIR + 'model.tflite'\n",
    "MODEL_TFLITE_MICRO = MODELS_DIR + 'model.cc'\n",
    "# Set seed for experiment reproducibility\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of steps within one time segment\n",
    "TIME_PERIODS = 80\n",
    "# The steps to take from one segment to the next; if this value is equal to\n",
    "# TIME_PERIODS, then there is no overlap between the segments\n",
    "STEP_DISTANCE = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = read_data('../data/data_adem.txt')\n",
    "df2 = read_data('../data/data_mathis.txt')\n",
    "df2 = df2[df2['activity'] != 'Jogging']\n",
    "\n",
    "df = pd.concat([df1, df2])\n",
    "# df = df1\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels from data\n",
    "LABELS = df[\"activity\"].unique()\n",
    "print(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column name of the label vector\n",
    "LABEL = \"ActivityEncoded\"\n",
    "# Transform the labels from String to Integer via LabelEncoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "# Add a new column to the existing DataFrame with the encoded values\n",
    "df[LABEL] = le.fit_transform(df[\"activity\"].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.round({'x-axis': 6, 'y-axis': 6, 'z-axis': 6})\n",
    "x_test, y_test = create_segments_and_labels(df,\n",
    "                                            TIME_PERIODS,\n",
    "                                            STEP_DISTANCE,\n",
    "                                            LABEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3h7IcvuOOS4J"
   },
   "source": [
    "## Generate a TensorFlow Lite Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sHe-Wv47rhm8"
   },
   "source": [
    "### 1. Generate Models with or without Quantization\n",
    "We now have an acceptably accurate model. We'll use the [TensorFlow Lite Converter](https://www.tensorflow.org/lite/convert) to convert the model into a special, space-efficient format for use on memory-constrained devices.\n",
    "\n",
    "Since this model is going to be deployed on a microcontroller, we want it to be as tiny as possible! One technique for reducing the size of a model is called [quantization](https://www.tensorflow.org/lite/performance/post_training_quantization). It reduces the precision of the model's weights, and possibly the activations (output of each layer) as well, which saves memory, often without much impact on accuracy. Quantized models also run faster, since the calculations required are simpler.\n",
    "\n",
    "In the following cell, we'll convert the model twice: once with quantization, once without."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1muAoUm8lSXL",
    "outputId": "aad8259e-df57-4f03-da77-d490e5609d9f"
   },
   "outputs": [],
   "source": [
    "# Convert the model to the TensorFlow Lite format without quantization\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_TF)\n",
    "model_no_quant_tflite = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(MODEL_NO_QUANT_TFLITE, \"wb\").write(model_no_quant_tflite)\n",
    "\n",
    "# Convert the model to the TensorFlow Lite format with quantization\n",
    "\n",
    "\n",
    "def representative_dataset():\n",
    "    for x in tf.data.Dataset.from_tensor_slices((x_test)).batch(1).take(100):\n",
    "        yield [tf.dtypes.cast(x, tf.float32)]\n",
    "\n",
    "\n",
    "# Set the optimization flag.\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# Enforce integer only quantization\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "# Provide a representative dataset to ensure we quantize correctly.\n",
    "converter.representative_dataset = representative_dataset\n",
    "model_tflite = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(MODEL_TFLITE, \"wb\").write(model_tflite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L_vE-ZDkHVxe"
   },
   "source": [
    "### 2. Compare Model Performance\n",
    "\n",
    "To prove these models are accurate even after conversion and quantization, we'll compare their predictions and loss on our test dataset.\n",
    "\n",
    "**Helper functions**\n",
    "\n",
    "We define the `predict` (for predictions) and `evaluate` (for loss) functions for TFLite models. *Note: These are already included in a TF model, but not in  a TFLite model.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_time_periods, num_sensors = x_test.shape[1], x_test.shape[2]\n",
    "input_shape = (TIME_PERIODS, num_sensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "id": "NKtmxEhko1S1"
   },
   "outputs": [],
   "source": [
    "def predict_tflite(tflite_model, x_test):\n",
    "    # Prepare the test data\n",
    "    x_test_ = x_test.copy()\n",
    "\n",
    "    # Initialize the TFLite interpreter\n",
    "    interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "    interpreter.resize_tensor_input(0, [1, input_shape[0], input_shape[1]],\n",
    "                                    strict=True)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    input_details = interpreter.get_input_details()[0]\n",
    "    output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "    # If required, quantize the input layer (from float to integer)\n",
    "    input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "    if (input_scale, input_zero_point) != (0.0, 0):\n",
    "        x_test_ = x_test_ / input_scale + input_zero_point\n",
    "        x_test_ = x_test_.astype(input_details[\"dtype\"])\n",
    "\n",
    "    # Invoke the interpreter\n",
    "    y_pred = []\n",
    "    for i in range(len(x_test_)):\n",
    "        interpreter.set_tensor(input_details[\"index\"], [x_test_[i]])\n",
    "        interpreter.invoke()\n",
    "        y_pred.append(interpreter.get_tensor(output_details[\"index\"]))\n",
    "    y_pred = np.asarray(y_pred, dtype=output_details['dtype'])\n",
    "    # If required, dequantized the output layer (from integer to float)\n",
    "    output_scale, output_zero_point = output_details[\"quantization\"]\n",
    "    if (output_scale, output_zero_point) != (0.0, 0):\n",
    "        y_pred = y_pred.astype(np.float32)\n",
    "        y_pred = (y_pred - output_zero_point) * output_scale\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def evaluate_tflite(tflite_model, x_test, y_true):\n",
    "    global model\n",
    "    y_pred = predict_tflite(tflite_model, x_test)\n",
    "    loss_function = tf.keras.losses.get(model.loss)\n",
    "    loss = loss_function(y_true, np.argmax(y_pred, axis=1)).numpy()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLZLY0D4gl6U"
   },
   "source": [
    "**1. Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(MODEL_TF)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0RS3zni1gkrt"
   },
   "outputs": [],
   "source": [
    "# Calculate predictions\n",
    "y_test_pred_tf = model.predict(x_test)\n",
    "y_test_pred_no_quant_tflite = predict_tflite(model_no_quant_tflite, x_test)\n",
    "y_test_pred_tflite = predict_tflite(model_tflite, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_no_quant_tflite = y_test_pred_no_quant_tflite.reshape(-1, 6)\n",
    "y_test_pred_tflite = y_test_pred_tflite.reshape(-1, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "-J7IKlXiYVPz",
    "outputId": "24017e5e-7672-460c-8b76-c0ed71f3ec27",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('========== TensorFlow ========== \\n')\n",
    "max_y_pred_tf = np.argmax(y_test_pred_tf, axis=1)\n",
    "cf_matrix = pd.DataFrame(confusion_matrix(y_test, max_y_pred_tf),\n",
    "                         columns=LABELS, index=LABELS)\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, fmt='.2%', cmap='Greens')\n",
    "print(classification_report(y_test, max_y_pred_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('======== TensorFlowLite ======== \\n')\n",
    "max_y_pred_nq_tflite = np.argmax(y_test_pred_no_quant_tflite, axis=1)\n",
    "cf_matrix = pd.DataFrame(confusion_matrix(y_test, max_y_pred_nq_tflite),\n",
    "                         columns=LABELS, index=LABELS)\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, fmt='.2%', cmap='Greens')\n",
    "print(classification_report(y_test, max_y_pred_nq_tflite))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('======= TFLite Quantized ======= \\n')\n",
    "max_y_pred_tflite = np.argmax(y_test_pred_tflite, axis=1)\n",
    "cf_matrix = pd.DataFrame(confusion_matrix(y_test, max_y_pred_tflite),\n",
    "                         columns=LABELS, index=LABELS)\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, fmt='.2%', cmap='Greens')\n",
    "print(classification_report(y_test, max_y_pred_tflite))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V7vlfJqbiZMU"
   },
   "source": [
    "**2. Loss (MSE/Mean Squared Error)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IpHifyGZRhw8"
   },
   "outputs": [],
   "source": [
    "# Calculate loss\n",
    "y_true = np.array(pd.get_dummies(y_test))\n",
    "loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
    "loss_tf, _ = model.evaluate(x_test, y_true, verbose=0)\n",
    "loss_nq_tflite = loss_function(y_true, y_test_pred_no_quant_tflite).numpy()\n",
    "loss_tflite = loss_function(y_true, y_test_pred_tflite).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "id": "g3HLT0UOjTY_",
    "outputId": "0c1c279a-96bd-4e8d-8a65-6a071376825b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compare loss\n",
    "df = pd.DataFrame.from_records(\n",
    "    [[\"TensorFlow\", loss_tf],\n",
    "     [\"TensorFlow Lite\", loss_nq_tflite],\n",
    "     [\"TensorFlow Lite Quantized\", loss_tflite]],\n",
    "    columns=[\"Model\", \"Loss/MSE\"], index=\"Model\").round(4)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E7Vjw7VckLu1"
   },
   "source": [
    "**3. Size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_size(dirpath):\n",
    "    size = 0\n",
    "    for path in os.listdir(dirpath):\n",
    "        if os.path.isfile(dirpath + '/' + path):\n",
    "            size += os.path.getsize(dirpath + '/' + path)\n",
    "        elif os.path.isdir(dirpath + '/' + path):\n",
    "            size += get_total_size(dirpath + '/' + path)\n",
    "    return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wEXiJ8dFkL2R"
   },
   "outputs": [],
   "source": [
    "# Calculate size\n",
    "size_tf = get_total_size(MODEL_TF)\n",
    "size_nq_tflite = os.path.getsize(MODEL_NO_QUANT_TFLITE)\n",
    "size_tflite = os.path.getsize(MODEL_TFLITE)\n",
    "\n",
    "tf_to_lite = 100*(size_tf - size_nq_tflite)/size_tf\n",
    "lite_to_quant = 100*(size_nq_tflite - size_tflite)/size_nq_tflite\n",
    "tf_to_quant = 100*(size_tf - size_tflite)/size_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "id": "8DdsCaL7kL4u",
    "outputId": "9644f10d-0914-4939-b596-facb90e4b961"
   },
   "outputs": [],
   "source": [
    "# Compare size\n",
    "pd.DataFrame.from_records(\n",
    "    [[\"TensorFlow\", f\"{size_tf} bytes\", \"\"],\n",
    "     [\"TensorFlow Lite\", f\"{size_nq_tflite} bytes \",\n",
    "      f\"(reduced by  {tf_to_lite:.1f}%)\"],\n",
    "     [\"TensorFlow Lite Quantized\", f\"{size_tflite} bytes\",\n",
    "      f\"(reduced by {lite_to_quant:.1f}%, total: {tf_to_quant:.1f}%)\"]],\n",
    "    columns=[\"Model\", \"Size\", \"\"], index=\"Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXdmfo7imGMB"
   },
   "source": [
    "**Summary**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R1LVMA2nkM_l"
   },
   "source": [
    "We can see from the predictions (graph) and loss (table) that the original TF model, the TFLite model, and the quantized TFLite model are all close enough to be indistinguishable - even though they differ in size (table). This implies that the quantized (smallest) model is ready to use!\n",
    "\n",
    "*Note: The quantized (integer) TFLite model is just 300 bytes smaller than the original (float) TFLite model - a tiny reduction in size! This is because the model is already so small that quantization has little effect. Complex models with more weights, can have upto a 4x reduction in size!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HPSFmDL7pv2L"
   },
   "source": [
    "## Generate a TensorFlow Lite for Microcontrollers Model\n",
    "Convert the TensorFlow Lite quantized model into a C source file that can be loaded by TensorFlow Lite for Microcontrollers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j1FB4ieeg0lw",
    "outputId": "c25b75c6-a28d-47b1-9b3a-b7ba821ee310"
   },
   "outputs": [],
   "source": [
    "# Install xxd if it is not available\n",
    "# !apt-get update && apt-get -qq install xxd\n",
    "# Convert to a C source file, i.e, a TensorFlow Lite for Microcontrollers model\n",
    "# !xxd -i {MODEL_TFLITE} > {MODEL_TFLITE_MICRO}\n",
    "# Update variable names\n",
    "# REPLACE_TEXT = MODEL_TFLITE.replace('/', '_').replace('.', '_')\n",
    "# !sed -i 's/'{REPLACE_TEXT}'/g_model/g' {MODEL_TFLITE_MICRO}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JvRy0ZyMhQOX"
   },
   "source": [
    "## Deploy to a Microcontroller\n",
    "\n",
    "Follow the instructions in the [hello_world](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro/examples/hello_world) README.md for [TensorFlow Lite for MicroControllers](https://www.tensorflow.org/lite/microcontrollers/overview) to deploy this model on a specific microcontroller.\n",
    "\n",
    "**Reference Model:** If you have not modified this notebook, you can follow the instructions as is, to deploy the model. Refer to the [`hello_world/train/models`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/hello_world/train/models) directory to access the models generated in this notebook.\n",
    "\n",
    "**New Model:** If you have generated a new model, then update the values assigned to the variables defined in [`hello_world/model.cc`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/hello_world/model.cc) with values displayed after running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l4-WhtGpvb-E",
    "outputId": "4c7925a5-4cf3-4f7a-fcbc-c8c2857423ea"
   },
   "outputs": [],
   "source": [
    "# Print the C source file\n",
    "# !cat {MODEL_TFLITE_MICRO}"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "train_hello_world_model.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
