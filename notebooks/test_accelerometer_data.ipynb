{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9867ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Useful function for dealing with data, and classical machine learning\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "\n",
    "# Deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.models import load_model, save_model\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../src'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from helpers import (read_data,  # noqa E402\n",
    "                     create_segments_and_labels,\n",
    "                     save_converted_model,\n",
    "                     compare)\n",
    "\n",
    "# Set some standard parameters upfront\n",
    "pd.options.display.float_format = '{:.1f}'.format\n",
    "sns.set()  # Default seaborn look and feel\n",
    "plt.style.use('ggplot')\n",
    "print('keras version ', keras.__version__)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c6bb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of steps within one time segment\n",
    "TIME_PERIODS = 80\n",
    "# The steps to take from one segment to the next; if this value is equal to\n",
    "# TIME_PERIODS, then there is no overlap between the segments\n",
    "STEP_DISTANCE = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f022f027",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = read_data('../data/data_adem.txt')\n",
    "df2 = read_data('../data/data_mathis.txt')\n",
    "df2 = df2[df2['activity'] != 'Jogging']\n",
    "\n",
    "df = pd.concat([df1, df2])\n",
    "# df = df1\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f42960b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column name of the label vector\n",
    "LABEL = \"ActivityEncoded\"\n",
    "# Transform the labels from String to Integer via LabelEncoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "# Add a new column to the existing DataFrame with the encoded values\n",
    "df[LABEL] = le.fit_transform(df[\"activity\"].values.ravel())\n",
    "# Get the ordered list of labels\n",
    "LABELS = le.classes_\n",
    "print(f\"Labels: {LABELS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3fac96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbda944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_m = load_model('../models/cnn/saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf57e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.round({'x-axis': 6, 'y-axis': 6, 'z-axis': 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c09a976",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = create_segments_and_labels(df,\n",
    "                                  TIME_PERIODS,\n",
    "                                  STEP_DISTANCE,\n",
    "                                  LABEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f5f18d",
   "metadata": {},
   "source": [
    "Test the model on our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958a3e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = x, y\n",
    "y_test_neural = pd.get_dummies(y_test)\n",
    "\n",
    "score = model_m.evaluate(x_test, y_test_neural, verbose=1)\n",
    "\n",
    "print(f\"\\nAccuracy on test data: {score[1] * 100:.1f}%\")\n",
    "print(f\"\\nLoss on test data: {score[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdc0eec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_test = model_m.predict(x_test)\n",
    "# Take the class with the highest probability from the test predictions\n",
    "max_y_pred_test = np.argmax(y_pred_test, axis=1)\n",
    "\n",
    "cf_matrix = pd.DataFrame(confusion_matrix(y_test, max_y_pred_test),\n",
    "                         columns=LABELS, index=LABELS)\n",
    "sns.heatmap(cf_matrix / np.sum(cf_matrix), annot=True, fmt='.2%',\n",
    "            cmap='Greens')\n",
    "\n",
    "print(classification_report(y_test, max_y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344338c1",
   "metadata": {},
   "source": [
    "Train the model on our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12aa6dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = shuffle(x, y)\n",
    "\n",
    "x_train2, x_test2 = x[:int(0.8 * len(x))], x[int(0.8 * len(x)):]\n",
    "y_train2, y_test2 = y[:int(0.8 * len(y))], y[int(0.8 * len(y)):]\n",
    "y_train_one_hot2 = pd.get_dummies(y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0beddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following cell is used if we want to train the model with\n",
    "# new randomized weights, set the boolean below to True to do so\n",
    "use_new_weights = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c69cdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set class weight\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                  classes=np.unique(y_train2),\n",
    "                                                  y=y_train2)\n",
    "class_weights\n",
    "dict_weights = {}\n",
    "for i in range(len(class_weights)):\n",
    "    dict_weights[i] = class_weights[i]\n",
    "dict_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37031d66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if use_new_weights:\n",
    "    num_time_periods, num_sensors = x_train2.shape[1], x_train2.shape[2]\n",
    "    num_classes = le.classes_.size\n",
    "    input_shape = (TIME_PERIODS, num_sensors)\n",
    "\n",
    "    print(\"\\n--- Create neural network model ---\\n\")\n",
    "\n",
    "    # 1D CNN neural network\n",
    "    norm_layer = Normalization()\n",
    "    norm_layer.adapt(x_train2)\n",
    "\n",
    "    model_m = Sequential()\n",
    "    model_m.add(Conv1D(14, 10, activation='relu', input_shape=input_shape))\n",
    "    model_m.add(MaxPooling1D(3))\n",
    "    model_m.add(Conv1D(16, 10, activation='relu'))\n",
    "    model_m.add(GlobalAveragePooling1D())\n",
    "    model_m.add(Dropout(0.5))\n",
    "    model_m.add(Dense(num_classes, activation='softmax'))\n",
    "    print(model_m.summary())\n",
    "\n",
    "    # The EarlyStopping callback monitors training accuracy:\n",
    "    # if it fails to improve for two consecutive epochs,\n",
    "    # training stops early\n",
    "    callbacks_list = [\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath='best_model.{epoch:02d}-{val_loss:.2f}.h5',\n",
    "            monitor='val_loss', save_best_only=True),\n",
    "        keras.callbacks.EarlyStopping(monitor='accuracy', patience=1)\n",
    "    ]\n",
    "\n",
    "    model_m.compile(loss='categorical_crossentropy',\n",
    "                    optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a04846",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50\n",
    "EPOCHS = 150\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='best_model.{epoch:02d}-{val_loss:.2f}.h5',\n",
    "        monitor='val_loss', save_best_only=True),\n",
    "    keras.callbacks.EarlyStopping(monitor='accuracy', patience=5)\n",
    "]\n",
    "\n",
    "history = model_m.fit(x_train2,\n",
    "                      y_train_one_hot2,\n",
    "                      batch_size=BATCH_SIZE,\n",
    "                      epochs=EPOCHS,\n",
    "                      callbacks=callbacks_list,\n",
    "                      validation_split=0.2,\n",
    "                      verbose=1,\n",
    "                      )  # class_weight=dict_weights)\n",
    "# summarize history for accuracy and loss\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history['accuracy'], \"g--\",\n",
    "         label=\"Accuracy of training data\")\n",
    "plt.plot(history.history['val_accuracy'], \"g\",\n",
    "         label=\"Accuracy of validation data\")\n",
    "plt.plot(history.history['loss'], \"r--\",\n",
    "         label=\"Loss of training data\")\n",
    "plt.plot(history.history['val_loss'], \"r\",\n",
    "         label=\"Loss of validation data\")\n",
    "plt.title('Model Accuracy and Loss')\n",
    "plt.ylabel('Accuracy and Loss')\n",
    "plt.xlabel('Training Epoch')\n",
    "plt.ylim(0)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7182c4e7-4019-4130-b221-1df45cc9a649",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test_neural2 = pd.get_dummies(y_test2)\n",
    "\n",
    "score = model_m.evaluate(x_test2, y_test_neural2, verbose=1)\n",
    "\n",
    "print(f\"\\nAccuracy on test data: {score[1] * 100:.1f}%\")\n",
    "print(f\"\\nLoss on test data: {score[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b58bd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test2 = model_m.predict(x_test2)\n",
    "# Take the class with the highest probability from the test predictions\n",
    "max_y_pred_test2 = np.argmax(y_pred_test2, axis=1)\n",
    "\n",
    "cf_matrix = pd.DataFrame(confusion_matrix(y_test2, max_y_pred_test2),\n",
    "                         columns=LABELS, index=LABELS)\n",
    "sns.heatmap(cf_matrix / np.sum(cf_matrix), annot=True, fmt='.2%',\n",
    "            cmap='Greens')\n",
    "\n",
    "print(classification_report(y_test2, max_y_pred_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ca7711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model on the WISDM data\n",
    "df_test_3 = read_data('../data/WISDM.txt', column_names=['user-id',\n",
    "                                                         'activity',\n",
    "                                                         'timestamp',\n",
    "                                                         'x-axis',\n",
    "                                                         'y-axis',\n",
    "                                                         'z-axis'])\n",
    "df_test_3[LABEL] = le.fit_transform(df_test_3[\"activity\"].values.ravel())\n",
    "df_test_3 = df_test_3.round({'x-axis': 6, 'y-axis': 6, 'z-axis': 6})\n",
    "\n",
    "x_test_3, y_test_3 = create_segments_and_labels(df_test_3,\n",
    "                                                TIME_PERIODS,\n",
    "                                                STEP_DISTANCE,\n",
    "                                                LABEL)\n",
    "\n",
    "y_test_neural_3 = pd.get_dummies(y_test_3)\n",
    "\n",
    "score = model_m.evaluate(x_test_3, y_test_neural_3, verbose=1)\n",
    "\n",
    "print(f\"\\nAccuracy on test data: {score[1] * 100:.1f}%\")\n",
    "print(f\"\\nLoss on test data: {score[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89cae9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_3 = model_m.predict(x_test_3)\n",
    "# Take the class with the highest probability from the test predictions\n",
    "max_y_pred_test_3 = np.argmax(y_pred_test_3, axis=1)\n",
    "\n",
    "cf_matrix = pd.DataFrame(confusion_matrix(y_test_3, max_y_pred_test_3),\n",
    "                         columns=LABELS, index=LABELS)\n",
    "sns.heatmap(cf_matrix / np.sum(cf_matrix), annot=True, fmt='.2%',\n",
    "            cmap='Greens')\n",
    "\n",
    "print(classification_report(y_test_3, max_y_pred_test_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5078f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can save the trained model by running the following:\n",
    "save_model(model_m, '../models/cnn/saved2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99550207-77ee-4af3-8892-60f8a50099ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_dataset():\n",
    "    for x in tf.data.Dataset.from_tensor_slices((x_train2)).batch(1).take(100):\n",
    "        yield [tf.dtypes.cast(x, tf.float32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38108e61-28bd-40be-b587-86a29018a6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_m)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8 \n",
    "converter.inference_output_type = tf.int8\n",
    "converter.representative_dataset = representative_dataset\n",
    "converted = converter.convert()\n",
    "save_converted_model(converted, \"paf\", LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4d54ea-0643-4ff9-ae5e-2d560c956cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that we can load the converted model\n",
    "interpreter = tf.lite.Interpreter(model_content=converted)\n",
    "interpreter.allocate_tensors()\n",
    "print(\"Input:\", interpreter.get_input_details())\n",
    "print(\"Output:\", interpreter.get_output_details())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c4e26c-daba-4cd1-b14d-15d6216e3edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(interpreter.get_input_details()[0]['quantization'])\n",
    "print(interpreter.get_output_details()[0]['quantization'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0007a0d-0f4d-4f07-b74b-e93ad1203234",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_verif = [-8.334668,0.831072,0.524509,-19.172131,1.816622,0.948428,-17.723145,1.662144,3.489543,-12.130774,1.100511,1.718426,-7.408993,0.941243,1.472937,-1.081351,1.524430,-0.085023,-1.283731,0.783171,-0.443079,-12.764256,0.502954,0.350870,-19.416424,0.639470,5.247488,-13.894706,0.833467,4.226012,-9.366921,0.822689,2.887196,-5.401967,0.730481,3.847599,-0.404758,1.591491,1.178350,-4.155359,1.208287,1.638193,-17.365089,2.405797,3.946992,-17.921930,1.601071,6.442603,-10.030342,1.055006,4.267925,-8.123906,2.240541,3.981720,-2.559078,2.421365,1.051414,0.593965,1.398691,0.317340,-10.484198,-0.439486,0.239502,-20.066671,1.857338,-1.464554,-16.021482,-0.100591,2.371069,-8.672366,-0.337698,0.191602,-2.295626,-0.199984,1.095721,-5.714517,-2.435735,-0.646655,-11.906839,0.203577,-2.343527,-14.152170,-3.678750,0.962798,-13.462405,-1.975891,1.068179,-7.655680,-3.787723,1.781895,-5.657036,-1.057401,0.929268,-6.033054,-2.298021,-0.555645,-10.545271,-2.030977,-1.577120,-14.246774,2.463278,-0.635878,-13.765375,-5.210365,2.359094,-13.214520,-0.226329,1.277743,-5.967191,-2.768643,1.622626,-4.203259,0.283810,-0.734073,-6.252199,-3.042872,-1.723217,-11.626622,0.035925,-1.023871,-17.051342,-2.159110,-0.908910,-14.784455,-1.748364,2.070494,-11.572735,-1.330433,0.234712,-5.960006,-1.195115,0.073048,-2.860851,-0.488584,-0.243094,-5.417534,-2.947072,-2.317181,-13.610896,2.215393,-1.580713,-15.712525,-6.367159,0.041913,-15.144906,-2.245331,1.410666,-9.183702,-2.360292,1.040636,-3.923042,-0.378413,-0.366438,-4.497847,-2.838098,-0.402363,-9.849518,-2.870431,-0.754431,-17.573456,-1.240620,-2.539918,-13.907879,-5.301376,2.896776,-10.939252,-0.786764,0.373623,-5.689369,-1.478925,-2.068099,-3.026107,-0.364043,1.987866,-8.384963,-3.229684,-0.647853,-16.557968,2.420167,-1.322051,-15.367642,-4.514612,2.994972,-11.208692,-0.884960,1.448987,-7.555089,-0.979563,-2.380649,-3.993695,-0.129331,3.190166,-4.402046,-3.356620,0.057480,-13.699512,-0.087418,-2.941084,-17.459692,-3.982918,-0.402363,-12.815749,-2.074087,3.271597,-9.194480,-0.385598,-1.741179,-4.334985,-0.946033,-0.186812,-4.257147,-2.180665,1.574725,-12.394226,-3.100353,-0.192799,-17.444124,-4.382886,-0.676593,-12.507990,-2.948269,4.605623,-9.508227,-1.677711,0.311353,-3.860771,-2.405797,0.219144,-4.925358,-2.301614,-0.247885,-12.507990,-0.043110,-1.356779,-12.484039,-3.518284,0.428708,-8.776549,-2.054927,1.304088,]\n",
    "input_verif = np.array(input_verif).reshape((1, 80, 3))\n",
    "print(input_verif[0, :5])\n",
    "output_verif = [0.964844,0.000000,0.000000,0.000000,0.027344,0.007812,]\n",
    "\n",
    "print(LABELS)\n",
    "compare(input_verif, model_m, interpreter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f837862c-fd93-4aff-8cce-40be43525917",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_test = df[df[\"activity\"] == \"Walking\"][1000:][:80][\n",
    "    [\"x-axis\", \"y-axis\", \"z-axis\"]].to_numpy().reshape((1, 80, 3))\n",
    "print(input_test[0, :2])\n",
    "print(LABELS)\n",
    "print(\"Comparison:\", compare(input_test, model_m, interpreter))\n",
    "\n",
    "model_m.predict(\n",
    "    df[0:80][[\"x-axis\", \"y-axis\", \"z-axis\"]].values.reshape((-1, 80, 3),\n",
    "                                                            order='C'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3285627-9b6c-45d3-8fc1-3a5e636436ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[280:280 + 80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51c9b91-cad6-4862-b395-fcf792b14e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = model_m.predict(x)\n",
    "np.argmax(r, axis=1)\n",
    "print(df.head, x[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
